"use strict";(self.webpackChunkclickhouse_docs_2_3_0=self.webpackChunkclickhouse_docs_2_3_0||[]).push([[47871],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>g});var n=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),d=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=d(e.components);return n.createElement(l.Provider,{value:t},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),m=d(a),u=i,g=m["".concat(l,".").concat(u)]||m[u]||c[u]||r;return a?n.createElement(g,o(o({ref:t},p),{},{components:a})):n.createElement(g,o({ref:t},p))}));function g(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,o=new Array(r);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[m]="string"==typeof e?e:i,o[1]=s;for(var d=2;d<r;d++)o[d]=a[d];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},96110:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>r,metadata:()=>s,toc:()=>d});var n=a(87462),i=(a(67294),a(3905));const r={},o="Laion-400M dataset",s={unversionedId:"en/getting-started/example-datasets/laion",id:"en/getting-started/example-datasets/laion",title:"Laion-400M dataset",description:"The dataset contains 400 million images with English text. For more information follow this link. Laion provides even larger datasets (e.g. 5 billion). Working with them will be similar.",source:"@site/docs/en/getting-started/example-datasets/laion.md",sourceDirName:"en/getting-started/example-datasets",slug:"/en/getting-started/example-datasets/laion",permalink:"/docs/en/getting-started/example-datasets/laion",draft:!1,editUrl:"https://github.com/ClickHouse/ClickHouse/tree/master/docs/en/getting-started/example-datasets/laion.md",tags:[],version:"current",frontMatter:{},sidebar:"english",previous:{title:"GitHub Repo Analysis",permalink:"/docs/en/getting-started/example-datasets/github"},next:{title:'New York Public Library "What\'s on the Menu?" Dataset',permalink:"/docs/en/getting-started/example-datasets/menus"}},l={},d=[{value:"Prepare data",id:"prepare-data",level:2},{value:"Create table for laion",id:"create-table-for-laion",level:2},{value:"Check data in table without indexes",id:"check-data-in-table-without-indexes",level:2},{value:"Add indexes",id:"add-indexes",level:2},{value:"Scripts for embeddings",id:"scripts-for-embeddings",level:2},{value:"Text embeddings",id:"text-embeddings",level:3},{value:"Image embeddings",id:"image-embeddings",level:3}],p={toc:d},m="wrapper";function c(e){let{components:t,...a}=e;return(0,i.kt)(m,(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"laion-400m-dataset"},"Laion-400M dataset"),(0,i.kt)("p",null,"The dataset contains 400 million images with English text. For more information follow this ",(0,i.kt)("a",{parentName:"p",href:"https://laion.ai/blog/laion-400-open-dataset/"},"link"),". Laion provides even larger datasets (e.g. ",(0,i.kt)("a",{parentName:"p",href:"https://laion.ai/blog/laion-5b/"},"5 billion"),"). Working with them will be similar."),(0,i.kt)("p",null,"The dataset has prepared embeddings for texts and images. This will be used to demonstrate ",(0,i.kt)("a",{parentName:"p",href:"/docs/en/engines/table-engines/mergetree-family/annindexes"},"Approximate nearest neighbor search indexes"),"."),(0,i.kt)("h2",{id:"prepare-data"},"Prepare data"),(0,i.kt)("p",null,"Embeddings are stored in ",(0,i.kt)("inlineCode",{parentName:"p"},".npy")," files, so we have to read them with python and merge with other data."),(0,i.kt)("p",null,"Download data and process it with simple ",(0,i.kt)("inlineCode",{parentName:"p"},"download.sh")," script:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"wget --tries=100 https://deploy.laion.ai/8f83b608504d46bb81708ec86e912220/embeddings/img_emb/img_emb_${1}.npy\nwget --tries=100 https://deploy.laion.ai/8f83b608504d46bb81708ec86e912220/embeddings/metadata/metadata_${1}.parquet\nwget --tries=100 https://deploy.laion.ai/8f83b608504d46bb81708ec86e912220/embeddings/text_emb/text_emb_${1}.npy\npython3 process.py ${1}\n")),(0,i.kt)("p",null,"Where ",(0,i.kt)("inlineCode",{parentName:"p"},"process.py"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"import pandas as pd\nimport numpy as np\nimport os\nimport sys\n\nstr_i = str(sys.argv[1])\nnpy_file = \"img_emb_\" + str_i + '.npy'\nmetadata_file = \"metadata_\" + str_i + '.parquet'\ntext_npy =  \"text_emb_\" + str_i + '.npy'\n\n# load all files\nim_emb = np.load(npy_file)\ntext_emb = np.load(text_npy) \ndata = pd.read_parquet(metadata_file)\n\n# combine them\ndata = pd.concat([data, pd.DataFrame({\"image_embedding\" : [*im_emb]}), pd.DataFrame({\"text_embedding\" : [*text_emb]})], axis=1, copy=False)\n\n# you can save more columns\ndata = data[['url', 'caption', 'similarity', \"image_embedding\", \"text_embedding\"]]\n\n# transform np.arrays to lists\ndata['image_embedding'] = data['image_embedding'].apply(lambda x: list(x))\ndata['text_embedding'] = data['text_embedding'].apply(lambda x: list(x))\n\n# this small hack is needed becase caption sometimes contains all kind of quotes\ndata['caption'] = data['caption'].apply(lambda x: x.replace(\"'\", \" \").replace('\"', \" \"))\n\n# save data to file\ndata.to_csv(str_i + '.csv', header=False)\n\n# previous files can be removed\nos.system(f\"rm {npy_file} {metadata_file} {text_npy}\")\n")),(0,i.kt)("p",null,"You can download data with"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"seq 0 409 | xargs -P100 -I{} bash -c './download.sh {}'\n")),(0,i.kt)("p",null,"The dataset is divided into 409 files. If you want to work only with a certain part of the dataset, just change the limits."),(0,i.kt)("h2",{id:"create-table-for-laion"},"Create table for laion"),(0,i.kt)("p",null,"Without indexes table can be created by"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE laion_dataset\n(\n    `id` Int64,\n    `url` String,\n    `caption` String,\n    `similarity` Float32,\n    `image_embedding` Array(Float32),\n    `text_embedding` Array(Float32)\n)\nENGINE = MergeTree\nORDER BY id\nSETTINGS index_granularity = 8192\n")),(0,i.kt)("p",null,"Fill table with data:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO laion_dataset FROM INFILE '{path_to_csv_files}/*.csv'\n")),(0,i.kt)("h2",{id:"check-data-in-table-without-indexes"},"Check data in table without indexes"),(0,i.kt)("p",null,"Let's check the work of the following query on the part of the dataset (8 million records):"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"select url, caption from test_laion where similarity > 0.2 order by L2Distance(image_embedding, {target:Array(Float32)}) limit 30\n")),(0,i.kt)("p",null,"Since the embeddings for images and texts may not match, let's also require a certain threshold of matching accuracy to get images that are more likely to satisfy our queries. The client parameter ",(0,i.kt)("inlineCode",{parentName:"p"},"target"),", which is an array of 512 elements. See later in this article for a convenient way of obtaining such vectors. I used a random picture of a cat from the Internet as a target vector."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"The result")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"\u250c\u2500url\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500caption\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 https://s3.amazonaws.com/filestore.rescuegroups.org/6685/pictures/animals/13884/13884995/63318230_463x463.jpg \u2502 Adoptable Female Domestic Short Hair                                   \u2502\n\u2502 https://s3.amazonaws.com/pet-uploads.adoptapet.com/8/b/6/239905226.jpg                                        \u2502 Adopt A Pet :: Marzipan - New York, NY                                 \u2502\n\u2502 http://d1n3ar4lqtlydb.cloudfront.net/9/2/4/248407625.jpg                                                      \u2502 Adopt A Pet :: Butterscotch - New Castle, DE                           \u2502\n\u2502 https://s3.amazonaws.com/pet-uploads.adoptapet.com/e/e/c/245615237.jpg                                        \u2502 Adopt A Pet :: Tiggy - Chicago, IL                                     \u2502\n\u2502 http://pawsofcoronado.org/wp-content/uploads/2012/12/rsz_pumpkin.jpg                                          \u2502 Pumpkin an orange tabby  kitten for adoption                           \u2502\n\u2502 https://s3.amazonaws.com/pet-uploads.adoptapet.com/7/8/3/188700997.jpg                                        \u2502 Adopt A Pet :: Brian the Brad Pitt of cats - Frankfort, IL             \u2502\n\u2502 https://s3.amazonaws.com/pet-uploads.adoptapet.com/8/b/d/191533561.jpg                                        \u2502 Domestic Shorthair Cat for adoption in Mesa, Arizona - Charlie         \u2502\n\u2502 https://s3.amazonaws.com/pet-uploads.adoptapet.com/0/1/2/221698235.jpg                                        \u2502 Domestic Shorthair Cat for adoption in Marietta, Ohio - Daisy (Spayed) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n8 rows in set. Elapsed: 6.432 sec. Processed 19.65 million rows, 43.96 GB (3.06 million rows/s., 6.84 GB/s.)\n")),(0,i.kt)("h2",{id:"add-indexes"},"Add indexes"),(0,i.kt)("p",null,"Create a new table or follow instructions from ",(0,i.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/alter/skipping-index"},"alter documentation"),"."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE laion_dataset\n(\n    `id` Int64,\n    `url` String,\n    `caption` String,\n    `similarity` Float32,\n    `image_embedding` Array(Float32),\n    `text_embedding` Array(Float32),\n    INDEX annoy_image image_embedding TYPE annoy(1000) GRANULARITY 1000,\n    INDEX annoy_text text_embedding TYPE annoy(1000) GRANULARITY 1000\n)\nENGINE = MergeTree\nORDER BY id\nSETTINGS index_granularity = 8192\n")),(0,i.kt)("p",null,"When created, the index will be built by L2Distance. You can read more about the parameters in the ",(0,i.kt)("a",{parentName:"p",href:"/docs/en/engines/table-engines/mergetree-family/annindexes#annoy-annoy"},"annoy documentation"),". It makes sense to build indexes for a large number of granules. If you need good speed, then GRANULARITY should be several times larger than the expected number of results in the search.\nNow let's check again with the same query:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"select url, caption from test_indexes_laion where similarity > 0.2 order by L2Distance(image_embedding, {target:Array(Float32)}) limit 8\n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Result")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"\u250c\u2500url\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500caption\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 http://tse1.mm.bing.net/th?id=OIP.R1CUoYp_4hbeFSHBaaB5-gHaFj                                                                                                                         \u2502 bed bugs and pets can cats carry bed bugs pets adviser               \u2502\n\u2502 http://pet-uploads.adoptapet.com/1/9/c/1963194.jpg?336w                                                                                                                              \u2502 Domestic Longhair Cat for adoption in Quincy, Massachusetts - Ashley \u2502\n\u2502 https://thumbs.dreamstime.com/t/cat-bed-12591021.jpg                                                                                                                                 \u2502 Cat on bed Stock Image                                               \u2502\n\u2502 https://us.123rf.com/450wm/penta/penta1105/penta110500004/9658511-portrait-of-british-short-hair-kitten-lieing-at-sofa-on-sun.jpg                                                    \u2502 Portrait of british short hair kitten lieing at sofa on sun.         \u2502\n\u2502 https://www.easypetmd.com/sites/default/files/Wirehaired%20Vizsla%20(2).jpg                                                                                                          \u2502 Vizsla (Wirehaired) image 3                                          \u2502\n\u2502 https://images.ctfassets.net/yixw23k2v6vo/0000000200009b8800000000/7950f4e1c1db335ef91bb2bc34428de9/dog-cat-flickr-Impatience_1.jpg?w=600&h=400&fm=jpg&fit=thumb&q=65&fl=progressive \u2502 dog and cat image                                                    \u2502\n\u2502 https://i1.wallbox.ru/wallpapers/small/201523/eaa582ee76a31fd.jpg                                                                                                                    \u2502 cats, kittens, faces, tonkinese                                      \u2502\n\u2502 https://www.baxterboo.com/images/breeds/medium/cairn-terrier.jpg                                                                                                                     \u2502 Cairn Terrier Photo                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n8 rows in set. Elapsed: 0.641 sec. Processed 22.06 thousand rows, 49.36 MB (91.53 thousand rows/s., 204.81 MB/s.)\n")),(0,i.kt)("p",null,"The speed has increased significantly. But now, the results sometimes differ from what you are looking for. This is due to the approximation of the search and the quality of the constructed embedding. Note that the example was given for picture embeddings, but there are also text embeddings in the dataset, which can also be used for searching."),(0,i.kt)("h2",{id:"scripts-for-embeddings"},"Scripts for embeddings"),(0,i.kt)("p",null,"Usually, we do not want to get embeddings from existing data, but to get them for new data and look for similar ones in old data. We can use ",(0,i.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/functions/#sql-user-defined-functions"},"UDF")," for this purpose. They will allow you to set the ",(0,i.kt)("inlineCode",{parentName:"p"},"target")," vector without leaving the client. All of the following scripts will be written for the ",(0,i.kt)("inlineCode",{parentName:"p"},"ViT-B/32")," model, as it was used for this dataset. You can use any model, but it is necessary to build embeddings in the dataset and for new objects using the same model."),(0,i.kt)("h3",{id:"text-embeddings"},"Text embeddings"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"encode_text.py"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'#!/usr/bin/python3\nimport clip\nimport torch\nimport numpy as np\nimport sys\n\nif __name__ == \'__main__\':\n    device = "cuda" if torch.cuda.is_available() else "cpu"\n    model, preprocess = clip.load("ViT-B/32", device=device)\n    for text in sys.stdin:\n        inputs = clip.tokenize(text)\n        with torch.no_grad():\n            text_features = model.encode_text(inputs)[0].tolist()\n        sys.stdout.flush()\n')),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"encode_text_function.xml"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-xml"},"<functions>\n    <function>\n        <type>executable</type>\n        <name>encode_text</name>\n        <return_type>Array(Float32)</return_type>\n        <argument>\n            <type>String</type>\n            <name>text</name>\n        </argument>\n        <format>TabSeparated</format>\n        <command>encode_text.py</command>\n        <command_read_timeout>1000000</command_read_timeout>\n    </function>\n</functions>\n")),(0,i.kt)("p",null,"Now we can simply use:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT encode_text('cat');\n")),(0,i.kt)("p",null,"The first use will be slow because the model needs to be loaded. But repeated queries will be fast. Then we copy the results to ",(0,i.kt)("inlineCode",{parentName:"p"},"set param_target=...")," and can easily write queries "),(0,i.kt)("h3",{id:"image-embeddings"},"Image embeddings"),(0,i.kt)("p",null,"For pictures, the process is similar, but you send the path instead of the picture (if necessary, you can implement a download picture with processing, but it will take longer)"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"encode_picture.py")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'#!/usr/bin/python3\nimport clip\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport sys\n\nif __name__ == \'__main__\':\n    device = "cuda" if torch.cuda.is_available() else "cpu"\n    model, preprocess = clip.load("ViT-B/32", device=device)\n    for text in sys.stdin:\n        image = preprocess(Image.open(text.strip())).unsqueeze(0).to(device)\n        with torch.no_grad():\n            image_features = model.encode_image(image)[0].tolist()\n        print(image_features)\n        sys.stdout.flush()\n')),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"encode_picture_function.xml")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-xml"},"<functions>\n    <function>\n        <type>executable_pool</type>\n        <name>encode_picture</name>\n        <return_type>Array(Float32)</return_type>\n        <argument>\n            <type>String</type>\n            <name>path</name>\n        </argument>\n        <format>TabSeparated</format>\n        <command>encode_picture.py</command>\n        <command_read_timeout>1000000</command_read_timeout>\n    </function>\n</functions>\n")),(0,i.kt)("p",null,"The query:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT encode_picture('some/path/to/your/picture');\n")))}c.isMDXComponent=!0}}]);